{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Create Tensorflow object called tensor\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x : 'Hello world'})\n",
    "    print(output)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array('Test String', dtype=object), array([123,  23]), array(45.67, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run([x,y,z], feed_dict={x: 'Test String', y : [123,23], z: 45.67})\n",
    "    print(output)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Math\n",
    "basic math function: add, sub, mul,div\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_guides/python/math_ops\">tensorflow doc</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.add : It takes in two numbers, two tensors, or one of each, and returns their sum as tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting types\n",
    "\n",
    "tf.subtract(tf.constant(2.0),tf.constant(1))  \n",
    "- Fails with ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int32\n",
    "\n",
    "\n",
    "-> tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "#z = tf.subtract(tf.cast(x/y , tf.int32) , tf.constant(1))\n",
    "z = tf.subtract(tf.divide(x,y),tf.cast(tf.constant(1), tf.float64))\n",
    "\n",
    "# TODO: Print z from a session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)\n",
    "sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Linear functions in TensorFlow\n",
    " $y = xW +b$\n",
    " \n",
    " The goal of training a neural network is to modify weights and biases to best predict the labels. In order to use weights and bias, you'll need a Tensor that can be modified. This leaves out __tf.placeholder()__ and __tf.constant()__, since those Tensors can't be modified. This is where __tf.Variable class__ comes in.\n",
    " \n",
    " \n",
    " The __tf.Variable class__ creates a tensor with an initial value that can be modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.Tensorflow Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow as tf\n",
    "reset_graph()\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # TODO: Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # TODO: Feed in the logit data\n",
    "        output = sess.run(softmax, feed_dict = {logits: logit_data} )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.Tensorflow Cross Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n",
      "0.35667497\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "\n",
    "x = -tf.reduce_sum(tf.multiply(tf.log(softmax), one_hot))\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x , feed_dict={one_hot : one_hot_data, softmax : softmax_data})\n",
    "    print(one_hot.shape);\n",
    "    print(output);\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.Mini-batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(55000 * 784 * 4)/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55000 * 10 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 10 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000-(128* 390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['F11', 'F12', 'F13', 'F14'],\n",
      "  ['F21', 'F22', 'F23', 'F24'],\n",
      "  ['F31', 'F32', 'F33', 'F34']],\n",
      " [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "last=0\n",
    "a = example_features[:batch_size]\n",
    "b = example_labels[:batch_size]\n",
    "c = list()\n",
    "c.append(list(a))\n",
    "c.append(list(b))\n",
    "pprint(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    output_batches = []\n",
    "    size = len(features)\n",
    "    for start in range(0, size, batch_size):\n",
    "        batch = [features[start:start+batch_size], labels[start:start+batch_size]]\n",
    "        output_batches.append(batch)\n",
    "    return output_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['F11', 'F12', 'F13', 'F14'], ['F21', 'F22', 'F23', 'F24'], ['F31', 'F32', 'F33', 'F34']], [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]], [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n",
      "\n",
      "[['F11', 'F12', 'F13', 'F14'], ['F21', 'F22', 'F23', 'F24'], ['F31', 'F32', 'F33', 'F34']]\n",
      "[['F41', 'F42', 'F43', 'F44']]\n"
     ]
    }
   ],
   "source": [
    "output_batches = batches(3, example_features, example_labels)\n",
    "print(output_batches);\n",
    "print(sep='n')\n",
    "for a,b in output_batches:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Save and Restore Tensorflow models\n",
    "\n",
    "__tf.train.Saver__ provides the functionality to save any tf.Variable to your file system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:\n",
      "[[ 1.1698422  -0.03154052  0.00813456]\n",
      " [-1.1060227  -0.29051888 -0.8664925 ]]\n",
      "Bias:\n",
      "[ 0.79629385 -0.02807747 -1.2582786 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# file path\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# wieghts, bias\n",
    "weights = tf.Variable(tf.truncated_normal([2,3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Saver : to save/restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "    \n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using TensorFlow 0.11.0RC1 or newer, a file called \"model.ckpt.meta\" will also be created. This file contains the TensorFlow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0403 23:56:48.190932  2972 deprecation.py:323] From C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:\n",
      "[[ 1.1698422  -0.03154052  0.00813456]\n",
      " [-1.1060227  -0.29051888 -0.8664925 ]]\n",
      "Bias:\n",
      "[ 0.79629385 -0.02807747 -1.2582786 ]\n"
     ]
    }
   ],
   "source": [
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "    \n",
    "    #Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.train.Saver.restore() function loads the saved data into weights and bias.\n",
    "\n",
    "Since tf.train.Saver.restore() sets all the TensorFlow Variables, you don't need to call tf.global_variables_initializer()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0403 23:56:56.782208  2972 deprecation.py:323] From <ipython-input-18-65588277aa58>:12: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0403 23:56:56.783209  2972 deprecation.py:323] From C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0403 23:56:56.783709  2972 deprecation.py:323] From C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0403 23:56:57.004748  2972 deprecation.py:323] From C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0403 23:56:57.006248  2972 deprecation.py:323] From C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0403 23:56:57.049756  2972 deprecation.py:323] From C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0403 23:56:57.297799  2972 deprecation.py:323] From <ipython-input-18-65588277aa58>:27: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove previous Tehnsors and Opeartions\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import mnist data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# features and labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights and bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits = xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.15320000052452087\n",
      "Epoch 10  - Validation Accuracy: 0.2919999957084656\n",
      "Epoch 20  - Validation Accuracy: 0.40540000796318054\n",
      "Epoch 30  - Validation Accuracy: 0.4975999891757965\n",
      "Epoch 40  - Validation Accuracy: 0.5626000165939331\n",
      "Epoch 50  - Validation Accuracy: 0.6128000020980835\n",
      "Epoch 60  - Validation Accuracy: 0.6456000208854675\n",
      "Epoch 70  - Validation Accuracy: 0.6723999977111816\n",
      "Epoch 80  - Validation Accuracy: 0.6934000253677368\n",
      "Epoch 90  - Validation Accuracy: 0.7081999778747559\n",
      "Trained Model Saved.\n"
     ]
    }
   ],
   "source": [
    "save_file = './train_model.ckpt'\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7303000092506409\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning\n",
    "\n",
    "Sometimes you might want to adjust, or \"finetune\" a model that you have already trained and saved.\n",
    "However, loading saved Variables directly into a modified model can generate errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Error\n",
    "\n",
    "TensorFlow uses a string identifier for Tensors and Operations called __name__\n",
    "\n",
    "TensorFlow will give the first node the name __Type__, and then give the name __Type_number__ for the subsequent nodes. \n",
    "\n",
    "Let's see how this can affect loading a model with a different order of weights and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: Variable:0\n",
      "Save Bias: Variable_1:0\n",
      "Save Bias: Placeholder:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = './naiming_error.ckpt'\n",
    "\n",
    "weigts = tf.Variable(tf.truncated_normal([2,3]))\n",
    "bias  =  tf.Variable(tf.truncated_normal([3]))\n",
    "test = tf.placeholder(tf.float32)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "print('Save Bias: {}'.format(test.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Weights: Variable_1:0\n",
      "Load Bias: Variable:0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-22-51b30991ae84>:8) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save/Assign_1:\n Variable_1 (defined at <ipython-input-22-51b30991ae84>:6)\n\nOriginal stack trace for 'save/Assign_1':\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-51b30991ae84>\", line 8, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\n    self.build()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\", line 72, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 70, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[{{node save/Assign_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1285\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1286\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-22-51b30991ae84>:8) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save/Assign_1:\n Variable_1 (defined at <ipython-input-22-51b30991ae84>:6)\n\nOriginal stack trace for 'save/Assign_1':\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-51b30991ae84>\", line 8, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\n    self.build()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\", line 72, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 70, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-51b30991ae84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Load the weights and bias - ERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1320\u001b[0m       \u001b[1;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1322\u001b[1;33m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at <ipython-input-22-51b30991ae84>:8) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save/Assign_1:\n Variable_1 (defined at <ipython-input-22-51b30991ae84>:6)\n\nOriginal stack trace for 'save/Assign_1':\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-51b30991ae84>\", line 8, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 825, in __init__\n    self.build()\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\", line 72, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 70, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ty-kim\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - ERROR\n",
    "    saver.restore(sess, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the name properties for weights and bias are different than when you saved the model. This is why the code produces the \"Assign requires shapes of both tensors to match\" error. \n",
    "\n",
    "The code saver.restore(sess, save_file) is trying to __load weight data into bias__ and __bias data into weights.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: weights_0:0\n",
      "Save Bias: bias_0:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = './naming_error2.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Weights: weights_0:0\n",
      "Load Bias: bias_0:0\n",
      "Loaded Weights and Bias successfully.\n"
     ]
    }
   ],
   "source": [
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
